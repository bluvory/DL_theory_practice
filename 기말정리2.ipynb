{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 밑바닥부터시작하는딥러닝2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 자연어 처리란\n",
    "- NLP: Natural Language Processing 자연어를 처리하는 분야\n",
    "- 우리의 말을 컴퓨터에게 이해시키기 위한 기술"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 시소러스\n",
    "- 시소러스 thesaurus: 유의어사전\n",
    "- 뜻이 같은 단어(동의어) = 뜻이 비슷한 단어(유의어)\n",
    "- 단어 네트워크를 이용해 컴퓨터에게 단어 사이의 관계 가르침\n",
    "\n",
    "### 2.2.1 WordNet\n",
    "\n",
    "### 2.2.2 시소러스의 문제점\n",
    "- 시대 변화에 대응하기 어렵다\n",
    "- 사람을 쓰는 비용은 크다\n",
    "- 단어의 미묘한 차이를 표현할 수 없다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 통계 기반 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 파이썬으로 말뭉치 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you say goodbye and i say hello .\n",
      "['you', 'say', 'goodbye', 'and', 'i', 'say', 'hello', '.']\n"
     ]
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "\n",
    "text = text.lower()\n",
    "text = text.replace('.', ' .')\n",
    "print(text)\n",
    "\n",
    "words = text.split(' ')\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n",
      "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}\n"
     ]
    }
   ],
   "source": [
    "word_to_id = {}\n",
    "id_to_word = {}\n",
    "\n",
    "for word in words:\n",
    "    if word not in word_to_id:\n",
    "        new_id = len(word_to_id)\n",
    "        word_to_id[word] = new_id\n",
    "        id_to_word[new_id] = word\n",
    "        \n",
    "print(id_to_word)\n",
    "print(word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 1, 5, 6])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "corpus = [word_to_id[w] for w in words]\n",
    "corpus = np.array(corpus)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('.', ' .')\n",
    "    words = text.split(' ')\n",
    "    \n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "    \n",
    "    for word in words:\n",
    "        if word not in word_to_id:\n",
    "            new_id = len(word_to_id)\n",
    "            word_to_id[word] = new_id\n",
    "            id_to_word[new_id] = word\n",
    "            \n",
    "    corpus = np.array([word_to_id[w] for w in words])\n",
    "    \n",
    "    return corpus, word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6]\n",
      "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}\n",
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "source": [
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "print(corpus)\n",
    "print(word_to_id)\n",
    "print(id_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 단어의 분산 표현\n",
    "- 분산 표현: 단어의 의미를 정확하게 파악할 수 있는 벡터 표현\n",
    "\n",
    "### 2.3.3 분포 가설\n",
    "- 분포 가설: 단어의 의미는 주변 단어에 의해 형성된다\n",
    "- 즉 단어 자체에는 의미가 없고 그 단어가 사용된 '맥락'이 의미 형성\n",
    "- 맥락: 특정 단어를 중심에 둔 그 주변 단어\n",
    "- 윈도우 크기: 맥락의 크기 (주변 단어를 몇 개나 포함할지)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 동시발생행렬 co-occurrence matrix\n",
    "- 그 주변에 어떤 단어가 몇 번이나 등장하는지를 세어 집계하는 방법 (통계기반)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6]\n",
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.util import preprocess\n",
    "\n",
    "text = 'You say goodbye and i say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "print(corpus)\n",
    "print(id_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
    "    corpus_size = len(corpus)\n",
    "    co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
    "    \n",
    "    for idx, word_id in enumerate(corpus):\n",
    "        for i in range(1, window_size+1):\n",
    "            left_idx = idx - i\n",
    "            right_idx = idx + i\n",
    "            \n",
    "            if left_idx >= 0:\n",
    "                left_word_id = corpus[left_idx]\n",
    "                co_matrix[word_id, left_word_id] += 1\n",
    "                \n",
    "            if right_idx < corpus_size:\n",
    "                right_word_id = corpus[right_idx]\n",
    "                co_matrix[word_id, right_word_id] += 1\n",
    "                \n",
    "    return co_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(word_to_id)\n",
    "co_matrix = create_co_matrix(corpus, vocab_size)\n",
    "\n",
    "co_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5 벡터 간 유사도\n",
    "- 벡터 사이의 유사도 측정 => 코사인 유사도 cosine similarity\n",
    "\n",
    "### $ similarity(x, y) = {xy\\over||x||||y|| } $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# devide by zero error !\n",
    "def cos_similarity(x, y):\n",
    "    nx = x / np.sqrt(np.sum(x**2))\n",
    "    ny = y / np.sqrt(np.sum(y**2))\n",
    "    return np.dot(nx, ny)\n",
    "\n",
    "# + epsilon\n",
    "def cos_similarity(x, y, eps=1e-8):\n",
    "    nx = x / np.sqrt(np.sum(x**2) + eps)\n",
    "    ny = y / np.sqrt(np.sum(y**2) + eps)\n",
    "    return np.dot(nx, ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071067691154799\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.util import preprocess, create_co_matrix, cos_similarity\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "\n",
    "c0 = C[word_to_id['you']]\n",
    "c1 = C[word_to_id['i']]\n",
    "print(cos_similarity(c0, c1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.6 유사 단어의 랭킹 표시\n",
    "##### most_similar(query, word_to_id, id_to_word, word_matrix, top=5)\n",
    "- query: 검색어(단어)\n",
    "- word_to_id: 단어에서 단어ID로의 딕셔너리\n",
    "- id_to_word: 단어ID에서 단어로의 딕셔너리\n",
    "- word_matirx: 단어벡터들을 한데 모은 행렬, 각 행에는 대응하는 단어의 벡터가 저장되어 있다고 가정\n",
    "- top: 상위 몇 개까지 출력할지 결정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(query, word_to_id, id_to_word, word_matrix, top=5):\n",
    "    \n",
    "    # 1. 검색어 꺼낸다\n",
    "    if query not in word_to_id:\n",
    "        print(\"%s(을)를 찾을 수 없습니다.\" %query)\n",
    "        return\n",
    "    \n",
    "    print('\\n[query] ' + query)\n",
    "    query_id = word_to_id[query]\n",
    "    query_vec = word_matrix[query_id]\n",
    "    \n",
    "    \n",
    "    # 2. 코사인 유사도 계산\n",
    "    vocab_size = len(id_to_word)\n",
    "    similarity = np.zeros(vocab_size)\n",
    "    for i in range(vocab_size):\n",
    "        similarity[i] = cos_similarity(word_matrix[i], query_vec)\n",
    "        \n",
    "        \n",
    "    # 3. 코사인 유사도를 기준으로 내림차순 출력\n",
    "    count = 0\n",
    "    for i in (-1*similarity).argsort():   # 내림차순 index\n",
    "        if id_to_word[i] == query:\n",
    "            continue\n",
    "        print(' %s: %s' % (id_to_word[i], similarity[i]))\n",
    "        \n",
    "        count += 1\n",
    "        if count >= top:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query] you\n",
      " goodbye: 0.7071067691154799\n",
      " i: 0.7071067691154799\n",
      " hello: 0.7071067691154799\n",
      " say: 0.0\n",
      " and: 0.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.util import preprocess, create_co_matrix, cos_similarity\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "\n",
    "most_similar('you', word_to_id, id_to_word, C, top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 통계 기반 기법 개선하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 상호정보량\n",
    "#### 점별 상호정보량 (Pointwise Mutual Information, PMI)\n",
    "### $ PMI(x, y) = log_2{P(x,y)\\over P(x)P(y) } $\n",
    "- P(x): x가 일어날 확률\n",
    "- P(y): y가 일어날 확률\n",
    "- P(x, y): x와 y가 동시에 일어날 확률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 동시발생행렬 사용\n",
    "### $ PMI(x, y) = log_2{P(x,y)\\over P(x)P(y)} = log_2{{C(x, y)\\over N}\\over {{C(x) \\over N} {C(y) \\over N}}} = log_2{C(x,y)\\cdot N\\over C(x)C(y)} $\n",
    "- N: 말뭉치에 포함된 단어\n",
    "- C: 동시발생 행렬\n",
    "- C(x, y): x와 y가 동시발생하는 횟수\n",
    "- C(x), C(y): x, y의 등장 횟수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 양의 상호정보량 (Positive PMI, PPMI)\n",
    "### $ PPMI(x, y) = max(0, PMI(x, y)) $\n",
    "- PMI의 문제: 두 단어의 동시발생 횟수가 0이면 $log_20= -\\infty$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppmi(C, verbose=False, eps=1e-8):\n",
    "    M = np.zeros_like(C, dtype=np.float32)\n",
    "    N = np.sum(C)\n",
    "    S = np.sum(C, axis=0)\n",
    "    total = C.shape[0] * C.shape[1]\n",
    "    cnt = 0\n",
    "    \n",
    "    for i in range(C.shape[0]):\n",
    "        for j in range(C.shape[1]):\n",
    "            pmi = np.log2(C[i, j]*N / (S[i]*S[j]) + eps)\n",
    "            M[i, j] = max(0, pmi)\n",
    "            \n",
    "            if verbose:\n",
    "                cnt += 1\n",
    "                if cnt % (total // 100) == 0:\n",
    "                    print('%.1f%% 완료' %(100*cnt/total))\n",
    "                    \n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동시 발생 행렬\n",
      "[[0 1 0 0 0 0 0]\n",
      " [1 0 1 0 1 1 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0]]\n",
      "--------------------------------------------------\n",
      "PPMI\n",
      "[[0.    1.807 0.    0.    0.    0.    0.   ]\n",
      " [1.807 0.    0.807 0.    0.807 0.807 0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.    1.807 0.    1.807 0.    0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.807 0.    0.    0.    0.    2.807]\n",
      " [0.    0.    0.    0.    0.    2.807 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.util import preprocess, create_co_matrix, cos_similarity\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "W = ppmi(C)\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "print('동시 발생 행렬')\n",
    "print(C)\n",
    "print('-'*50)\n",
    "print('PPMI')\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 차원 감소 Dimensionality reduction\n",
    "- 중요한 정보는 최대한 유지하면서 차원 줄이기\n",
    "- 특이값 분해 (Singular Value Decomposition, SVD)\n",
    "### $ X = USV^T $\n",
    "\n",
    "\n",
    "- U, V: 직교행렬, S: 대각행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3 SVD에 의한 차원 감소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동시발생행렬: [0 1 0 0 0 0 0]\n",
      "PPMI행렬: [0.    1.807 0.    0.    0.    0.    0.   ]\n",
      "SVD: [-3.409e-01 -1.110e-16 -3.886e-16 -1.205e-01  0.000e+00  9.323e-01\n",
      "  2.226e-16]\n",
      "2차원벡터로 줄이기: [-3.409e-01 -1.110e-16]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.util import preprocess, create_co_matrix, cos_similarity\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "W = ppmi(C)\n",
    "\n",
    "U, S, V = np.linalg.svd(W)\n",
    "\n",
    "print(\"동시발생행렬:\", C[0])\n",
    "print(\"PPMI행렬:\", W[0])\n",
    "print(\"SVD:\", U[0])\n",
    "print(\"2차원벡터로 줄이기:\", U[0, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for word, word_id in word_to_id.items():\n",
    "    plt.annotate(word, (U[word_id, 0], U[word_id, 1]))\n",
    "    \n",
    "plt.scatter(U[:, 0], U[:, 1], alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 추론 기반 기법과 신경망\n",
    "\n",
    "### 3.1.1 통계 기반 기법의 문제접\n",
    "- 어휘가 너무 많아 이런 거대 행렬에 SVD를 적용하기 힘들다\n",
    "- 통계 기밥 기법(배치 학습) vs 추론 기밥 기법(미니배치 학습)\n",
    "\n",
    "### 3.1.2 추론 기반 기법 개요\n",
    "- 단어의 출현 패턴 학습\n",
    "- 모델은 맥락 정보를 입력받아 각 단어의 출현 확률을 출력\n",
    "\n",
    "### 3.1.3 신경망에서의 단어 처리\n",
    "- 원핫인코딩 one-hot encoding\n",
    "- 단어를 고정 길이 벡터로 변환하면 신경망의 입력층은 뉴련의 수를 고정할 수 있다\n",
    "### $ c \\cdot W = h $\n",
    "- 가중치의 행벡터 하나를 뽑아낸 것과 같은데 np.matmul 사용하면 계산량 많아진다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.391 -0.678 -1.069]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "c = np.array([[1,0,0,0,0,0,0]])   # 입력\n",
    "W = np.random.randn(7, 3)       # 가중치 \n",
    "h = np.matmul(c, W)             # 중간 노드\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.062  0.8    1.133]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.layers import MatMul\n",
    "\n",
    "C = np.array([[1,0,0,0,0,0,0]])\n",
    "W = np.random.randn(7, 3)\n",
    "layer = MatMul(W)\n",
    "h = layer.forward(C)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 단순한 word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 CBOW 모델의 추론 처리\n",
    "#### CBOW (continuous bag-of-words)\n",
    "- 맥락으로 부터 타깃(target)을 추측하는 용도의 신경망\n",
    "- $h_1$: 첫번째 입력층, $h_2$: 두번째 입력층\n",
    "- ${1 \\over 2} (h_1+h_2)$: 은닉층\n",
    "- $W_{in}$: 두 입력층 => 은닉층, 완전연결계층의 가중치(단어 분산 표현)\n",
    "- $W_{out}$: 은닉층 => 출력층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.073  1.558  1.394  3.299 -0.071 -2.75  -2.919]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.layers import MatMul\n",
    "\n",
    "# input: two words (one hot)\n",
    "c0 = np.array([[1,0,0,0,0,0,0]])   # you\n",
    "c1 = np.array([[0,0,1,0,0,0,0]])   # goodbye\n",
    "\n",
    "# weights: random\n",
    "W_in = np.random.randn(7, 3)\n",
    "W_out = np.random.randn(3, 7)\n",
    "\n",
    "# Layers\n",
    "in_layer_0 = MatMul(W_in)\n",
    "in_layer_1 = MatMul(W_in)\n",
    "out_layer = MatMul(W_out)\n",
    "\n",
    "# forward\n",
    "h0 = in_layer_0.forward(c0)\n",
    "h1 = in_layer_1.forward(c1)\n",
    "h = 0.5 * (h0 + h1)\n",
    "s = out_layer.forward(h)\n",
    "\n",
    "print(s)   # word's score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 CBOW 모델의 학습\n",
    "- 위의 각 단어의 점수를 출력한 걸 토대로 소프트맥스함수를 적용하면 \"확률\" 얻을 수 있음\n",
    "- CBOW 모델의 학습: 올바를 예측을 할 수 있도록 가중치 조정\n",
    "- $W_{in}$에 단어의 출현 패턴을 파악한 벡터 학습\n",
    "- 다중 클래스 분류를 수행함\n",
    "- 소프트맥스함수로 점수를 확률로 변환\n",
    "- 그 확률과 정답 레이블로부터 교차 엔트로피 오차 구한 후, 이 값을 손실로 사용해 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 word2vec의 가중치와 분산 표현\n",
    "입력, 완전연결계층의 가중치 $W_{in}$ : 각 행이 각 단어의 분산 표현\n",
    "\n",
    "출력, 완전연결계층의 가중치 $W_{out}$ : 단어의 의미가 인코딩된 벡터가 저장되고 있다\n",
    "\n",
    "1. 입력 층의 가중치만 이용  =>  word2vec\n",
    "2. 출력 층의 가중치만 이용\n",
    "3. 양쪽 가중치를 모두 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 학습 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 맥락과 타깃\n",
    "- 맥락: word2vec에서 이용하는 신경망의 입력\n",
    "- 타깃: 그 정답 레이블은 맥락에 둘러싸인 중앙의 단어\n",
    "- 신경망에 \"맥락\"을 입력했을 때 \"타깃\"이 출현할 확률 높이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6]\n",
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.util import preprocess\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "print(corpus)\n",
    "print(id_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context_target(corpus, window_size=1):\n",
    "    \n",
    "    target = corpus[window_size:-window_size]\n",
    "    contexts = []\n",
    "    \n",
    "    for idx in range(window_size, len(corpus) - window_size):\n",
    "        cs = []\n",
    "        for t in range(-window_size, window_size+1):\n",
    "            if t==0:\n",
    "                continue\n",
    "            cs.append(corpus[idx + t])\n",
    "            \n",
    "        contexts.append(cs)\n",
    "    return np.array(contexts), np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2]\n",
      " [1 3]\n",
      " [2 4]\n",
      " [3 1]\n",
      " [4 5]\n",
      " [1 6]]\n",
      "[1 2 3 4 1 5]\n"
     ]
    }
   ],
   "source": [
    "contexts, target = create_context_target(corpus, window_size=1)\n",
    "\n",
    "print(contexts)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 원핫 표현으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target:\n",
      " [[0 1 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0]]\n",
      "contexts:\n",
      " [[[1 0 0 0 0 0 0]\n",
      "  [0 0 1 0 0 0 0]]\n",
      "\n",
      " [[0 1 0 0 0 0 0]\n",
      "  [0 0 0 1 0 0 0]]\n",
      "\n",
      " [[0 0 1 0 0 0 0]\n",
      "  [0 0 0 0 1 0 0]]\n",
      "\n",
      " [[0 0 0 1 0 0 0]\n",
      "  [0 1 0 0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0 1 0 0]\n",
      "  [0 0 0 0 0 1 0]]\n",
      "\n",
      " [[0 1 0 0 0 0 0]\n",
      "  [0 0 0 0 0 0 1]]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.util import preprocess, create_contexts_target, convert_one_hot\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "contexts, target = create_contexts_target(corpus, window_size=1)\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "target = convert_one_hot(target, vocab_size)\n",
    "contexts = convert_one_hot(contexts, vocab_size)\n",
    "\n",
    "print(\"target:\\n\", target)\n",
    "print(\"contexts:\\n\", contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 CBOW 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.layers import MatMul, SoftmaxWithLoss\n",
    "\n",
    "class simpleCBOW:\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        V, H = vocab_size, hidden_size\n",
    "        \n",
    "        # 가중치 초기화\n",
    "        W_in = 0.01 * np.random.randn(V, H).astype('f')\n",
    "        W_out = 0.01 * np.random.randn(H, V).astype('f')\n",
    "        \n",
    "        # 계층 생성\n",
    "        self.in_layer0 = MatMul(W_in)\n",
    "        self.in_layer1 = MatMul(W_in)\n",
    "        self.out_layer = MatMul(W_out)\n",
    "        self.loss_layer = SoftmaxWithLoss()\n",
    "        \n",
    "        # 모든 가중치와 기울기를 리스트에 모은다\n",
    "        layers = [self.in_layer0, self.in_layer1, self.out_layer]\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "        # 인스턴스 변수에 단어의 분산 표현을 저장한다\n",
    "        self.word_vecs = W_in\n",
    "        \n",
    "        \n",
    "    def forward(self, contexts, target):\n",
    "        h0 = self.in_layer0.forward(contexts[:, 0])\n",
    "        h1 = self.in_layer1.forward(contexts[:, 1])\n",
    "        h = (h0 + h1) * 0.5\n",
    "        score = self.out_layer.forward(h)\n",
    "        loss = self.loss_layer.forward(score, target)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        ds = self.loss_layer.backward(dout)\n",
    "        da = self.out_layer.backward(ds)\n",
    "        da *= 0.5\n",
    "        self.in_layer1.backward(da)\n",
    "        self.in_layer0.backward(da)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 2 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 3 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 4 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 5 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 6 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 7 |  반복 1 / 2 | 시간 0[s] | 손실 1.95\n",
      "| 에폭 8 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 9 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 10 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 11 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 12 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 13 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 14 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 15 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 16 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 17 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 18 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 19 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 20 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 21 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 22 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 23 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 24 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 25 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 26 |  반복 1 / 2 | 시간 0[s] | 손실 1.94\n",
      "| 에폭 27 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 28 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 29 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 30 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 31 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 32 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 33 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 34 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 35 |  반복 1 / 2 | 시간 0[s] | 손실 1.93\n",
      "| 에폭 36 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
      "| 에폭 37 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
      "| 에폭 38 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
      "| 에폭 39 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
      "| 에폭 40 |  반복 1 / 2 | 시간 0[s] | 손실 1.92\n",
      "| 에폭 41 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
      "| 에폭 42 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
      "| 에폭 43 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
      "| 에폭 44 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
      "| 에폭 45 |  반복 1 / 2 | 시간 0[s] | 손실 1.91\n",
      "| 에폭 46 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
      "| 에폭 47 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
      "| 에폭 48 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
      "| 에폭 49 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
      "| 에폭 50 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
      "| 에폭 51 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
      "| 에폭 52 |  반복 1 / 2 | 시간 0[s] | 손실 1.90\n",
      "| 에폭 53 |  반복 1 / 2 | 시간 0[s] | 손실 1.88\n",
      "| 에폭 54 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
      "| 에폭 55 |  반복 1 / 2 | 시간 0[s] | 손실 1.89\n",
      "| 에폭 56 |  반복 1 / 2 | 시간 0[s] | 손실 1.88\n",
      "| 에폭 57 |  반복 1 / 2 | 시간 0[s] | 손실 1.88\n",
      "| 에폭 58 |  반복 1 / 2 | 시간 0[s] | 손실 1.87\n",
      "| 에폭 59 |  반복 1 / 2 | 시간 0[s] | 손실 1.88\n",
      "| 에폭 60 |  반복 1 / 2 | 시간 0[s] | 손실 1.87\n",
      "| 에폭 61 |  반복 1 / 2 | 시간 0[s] | 손실 1.87\n",
      "| 에폭 62 |  반복 1 / 2 | 시간 0[s] | 손실 1.86\n",
      "| 에폭 63 |  반복 1 / 2 | 시간 0[s] | 손실 1.86\n",
      "| 에폭 64 |  반복 1 / 2 | 시간 0[s] | 손실 1.86\n",
      "| 에폭 65 |  반복 1 / 2 | 시간 0[s] | 손실 1.87\n",
      "| 에폭 66 |  반복 1 / 2 | 시간 0[s] | 손실 1.85\n",
      "| 에폭 67 |  반복 1 / 2 | 시간 0[s] | 손실 1.85\n",
      "| 에폭 68 |  반복 1 / 2 | 시간 0[s] | 손실 1.84\n",
      "| 에폭 69 |  반복 1 / 2 | 시간 0[s] | 손실 1.85\n",
      "| 에폭 70 |  반복 1 / 2 | 시간 0[s] | 손실 1.83\n",
      "| 에폭 71 |  반복 1 / 2 | 시간 0[s] | 손실 1.83\n",
      "| 에폭 72 |  반복 1 / 2 | 시간 0[s] | 손실 1.84\n",
      "| 에폭 73 |  반복 1 / 2 | 시간 0[s] | 손실 1.82\n",
      "| 에폭 74 |  반복 1 / 2 | 시간 0[s] | 손실 1.83\n",
      "| 에폭 75 |  반복 1 / 2 | 시간 0[s] | 손실 1.82\n",
      "| 에폭 76 |  반복 1 / 2 | 시간 0[s] | 손실 1.83\n",
      "| 에폭 77 |  반복 1 / 2 | 시간 0[s] | 손실 1.81\n",
      "| 에폭 78 |  반복 1 / 2 | 시간 0[s] | 손실 1.81\n",
      "| 에폭 79 |  반복 1 / 2 | 시간 0[s] | 손실 1.82\n",
      "| 에폭 80 |  반복 1 / 2 | 시간 0[s] | 손실 1.79\n",
      "| 에폭 81 |  반복 1 / 2 | 시간 0[s] | 손실 1.82\n",
      "| 에폭 82 |  반복 1 / 2 | 시간 0[s] | 손실 1.79\n",
      "| 에폭 83 |  반복 1 / 2 | 시간 0[s] | 손실 1.79\n",
      "| 에폭 84 |  반복 1 / 2 | 시간 0[s] | 손실 1.80\n",
      "| 에폭 85 |  반복 1 / 2 | 시간 0[s] | 손실 1.77\n",
      "| 에폭 86 |  반복 1 / 2 | 시간 0[s] | 손실 1.77\n",
      "| 에폭 87 |  반복 1 / 2 | 시간 0[s] | 손실 1.77\n",
      "| 에폭 88 |  반복 1 / 2 | 시간 0[s] | 손실 1.79\n",
      "| 에폭 89 |  반복 1 / 2 | 시간 0[s] | 손실 1.76\n",
      "| 에폭 90 |  반복 1 / 2 | 시간 0[s] | 손실 1.77\n",
      "| 에폭 91 |  반복 1 / 2 | 시간 0[s] | 손실 1.75\n",
      "| 에폭 92 |  반복 1 / 2 | 시간 0[s] | 손실 1.77\n",
      "| 에폭 93 |  반복 1 / 2 | 시간 0[s] | 손실 1.75\n",
      "| 에폭 94 |  반복 1 / 2 | 시간 0[s] | 손실 1.74\n",
      "| 에폭 95 |  반복 1 / 2 | 시간 0[s] | 손실 1.73\n",
      "| 에폭 96 |  반복 1 / 2 | 시간 0[s] | 손실 1.75\n",
      "| 에폭 97 |  반복 1 / 2 | 시간 0[s] | 손실 1.73\n",
      "| 에폭 98 |  반복 1 / 2 | 시간 0[s] | 손실 1.73\n",
      "| 에폭 99 |  반복 1 / 2 | 시간 0[s] | 손실 1.72\n",
      "| 에폭 100 |  반복 1 / 2 | 시간 0[s] | 손실 1.75\n",
      "| 에폭 101 |  반복 1 / 2 | 시간 0[s] | 손실 1.68\n",
      "| 에폭 102 |  반복 1 / 2 | 시간 0[s] | 손실 1.73\n",
      "| 에폭 103 |  반복 1 / 2 | 시간 0[s] | 손실 1.68\n",
      "| 에폭 104 |  반복 1 / 2 | 시간 0[s] | 손실 1.74\n",
      "| 에폭 105 |  반복 1 / 2 | 시간 0[s] | 손실 1.68\n",
      "| 에폭 106 |  반복 1 / 2 | 시간 0[s] | 손실 1.70\n",
      "| 에폭 107 |  반복 1 / 2 | 시간 0[s] | 손실 1.66\n",
      "| 에폭 108 |  반복 1 / 2 | 시간 0[s] | 손실 1.70\n",
      "| 에폭 109 |  반복 1 / 2 | 시간 0[s] | 손실 1.71\n",
      "| 에폭 110 |  반복 1 / 2 | 시간 0[s] | 손실 1.63\n",
      "| 에폭 111 |  반복 1 / 2 | 시간 0[s] | 손실 1.68\n",
      "| 에폭 112 |  반복 1 / 2 | 시간 0[s] | 손실 1.68\n",
      "| 에폭 113 |  반복 1 / 2 | 시간 0[s] | 손실 1.67\n",
      "| 에폭 114 |  반복 1 / 2 | 시간 0[s] | 손실 1.63\n",
      "| 에폭 115 |  반복 1 / 2 | 시간 0[s] | 손실 1.66\n",
      "| 에폭 116 |  반복 1 / 2 | 시간 0[s] | 손실 1.64\n",
      "| 에폭 117 |  반복 1 / 2 | 시간 0[s] | 손실 1.62\n",
      "| 에폭 118 |  반복 1 / 2 | 시간 0[s] | 손실 1.67\n",
      "| 에폭 119 |  반복 1 / 2 | 시간 0[s] | 손실 1.61\n",
      "| 에폭 120 |  반복 1 / 2 | 시간 0[s] | 손실 1.64\n",
      "| 에폭 121 |  반복 1 / 2 | 시간 0[s] | 손실 1.62\n",
      "| 에폭 122 |  반복 1 / 2 | 시간 0[s] | 손실 1.61\n",
      "| 에폭 123 |  반복 1 / 2 | 시간 0[s] | 손실 1.65\n",
      "| 에폭 124 |  반복 1 / 2 | 시간 0[s] | 손실 1.60\n",
      "| 에폭 125 |  반복 1 / 2 | 시간 0[s] | 손실 1.55\n",
      "| 에폭 126 |  반복 1 / 2 | 시간 0[s] | 손실 1.62\n",
      "| 에폭 127 |  반복 1 / 2 | 시간 0[s] | 손실 1.61\n",
      "| 에폭 128 |  반복 1 / 2 | 시간 0[s] | 손실 1.54\n",
      "| 에폭 129 |  반복 1 / 2 | 시간 0[s] | 손실 1.61\n",
      "| 에폭 130 |  반복 1 / 2 | 시간 0[s] | 손실 1.59\n",
      "| 에폭 131 |  반복 1 / 2 | 시간 0[s] | 손실 1.57\n",
      "| 에폭 132 |  반복 1 / 2 | 시간 0[s] | 손실 1.56\n",
      "| 에폭 133 |  반복 1 / 2 | 시간 0[s] | 손실 1.60\n",
      "| 에폭 134 |  반복 1 / 2 | 시간 0[s] | 손실 1.49\n",
      "| 에폭 135 |  반복 1 / 2 | 시간 0[s] | 손실 1.57\n",
      "| 에폭 136 |  반복 1 / 2 | 시간 0[s] | 손실 1.57\n",
      "| 에폭 137 |  반복 1 / 2 | 시간 0[s] | 손실 1.57\n",
      "| 에폭 138 |  반복 1 / 2 | 시간 0[s] | 손실 1.48\n",
      "| 에폭 139 |  반복 1 / 2 | 시간 0[s] | 손실 1.55\n",
      "| 에폭 140 |  반복 1 / 2 | 시간 0[s] | 손실 1.51\n",
      "| 에폭 141 |  반복 1 / 2 | 시간 0[s] | 손실 1.53\n",
      "| 에폭 142 |  반복 1 / 2 | 시간 0[s] | 손실 1.48\n",
      "| 에폭 143 |  반복 1 / 2 | 시간 0[s] | 손실 1.54\n",
      "| 에폭 144 |  반복 1 / 2 | 시간 0[s] | 손실 1.49\n",
      "| 에폭 145 |  반복 1 / 2 | 시간 0[s] | 손실 1.53\n",
      "| 에폭 146 |  반복 1 / 2 | 시간 0[s] | 손실 1.52\n",
      "| 에폭 147 |  반복 1 / 2 | 시간 0[s] | 손실 1.48\n",
      "| 에폭 148 |  반복 1 / 2 | 시간 0[s] | 손실 1.50\n",
      "| 에폭 149 |  반복 1 / 2 | 시간 0[s] | 손실 1.52\n",
      "| 에폭 150 |  반복 1 / 2 | 시간 0[s] | 손실 1.48\n",
      "| 에폭 151 |  반복 1 / 2 | 시간 0[s] | 손실 1.48\n",
      "| 에폭 152 |  반복 1 / 2 | 시간 0[s] | 손실 1.42\n",
      "| 에폭 153 |  반복 1 / 2 | 시간 0[s] | 손실 1.48\n",
      "| 에폭 154 |  반복 1 / 2 | 시간 0[s] | 손실 1.44\n",
      "| 에폭 155 |  반복 1 / 2 | 시간 0[s] | 손실 1.47\n",
      "| 에폭 156 |  반복 1 / 2 | 시간 0[s] | 손실 1.49\n",
      "| 에폭 157 |  반복 1 / 2 | 시간 0[s] | 손실 1.41\n",
      "| 에폭 158 |  반복 1 / 2 | 시간 0[s] | 손실 1.43\n",
      "| 에폭 159 |  반복 1 / 2 | 시간 0[s] | 손실 1.46\n",
      "| 에폭 160 |  반복 1 / 2 | 시간 0[s] | 손실 1.42\n",
      "| 에폭 161 |  반복 1 / 2 | 시간 0[s] | 손실 1.44\n",
      "| 에폭 162 |  반복 1 / 2 | 시간 0[s] | 손실 1.46\n",
      "| 에폭 163 |  반복 1 / 2 | 시간 0[s] | 손실 1.38\n",
      "| 에폭 164 |  반복 1 / 2 | 시간 0[s] | 손실 1.41\n",
      "| 에폭 165 |  반복 1 / 2 | 시간 0[s] | 손실 1.46\n",
      "| 에폭 166 |  반복 1 / 2 | 시간 0[s] | 손실 1.36\n",
      "| 에폭 167 |  반복 1 / 2 | 시간 0[s] | 손실 1.38\n",
      "| 에폭 168 |  반복 1 / 2 | 시간 0[s] | 손실 1.41\n",
      "| 에폭 169 |  반복 1 / 2 | 시간 0[s] | 손실 1.38\n",
      "| 에폭 170 |  반복 1 / 2 | 시간 0[s] | 손실 1.39\n",
      "| 에폭 171 |  반복 1 / 2 | 시간 0[s] | 손실 1.39\n",
      "| 에폭 172 |  반복 1 / 2 | 시간 0[s] | 손실 1.38\n",
      "| 에폭 173 |  반복 1 / 2 | 시간 0[s] | 손실 1.40\n",
      "| 에폭 174 |  반복 1 / 2 | 시간 0[s] | 손실 1.30\n",
      "| 에폭 175 |  반복 1 / 2 | 시간 0[s] | 손실 1.42\n",
      "| 에폭 176 |  반복 1 / 2 | 시간 0[s] | 손실 1.37\n",
      "| 에폭 177 |  반복 1 / 2 | 시간 0[s] | 손실 1.37\n",
      "| 에폭 178 |  반복 1 / 2 | 시간 0[s] | 손실 1.34\n",
      "| 에폭 179 |  반복 1 / 2 | 시간 0[s] | 손실 1.37\n",
      "| 에폭 180 |  반복 1 / 2 | 시간 0[s] | 손실 1.35\n",
      "| 에폭 181 |  반복 1 / 2 | 시간 0[s] | 손실 1.32\n",
      "| 에폭 182 |  반복 1 / 2 | 시간 0[s] | 손실 1.34\n",
      "| 에폭 183 |  반복 1 / 2 | 시간 0[s] | 손실 1.29\n",
      "| 에폭 184 |  반복 1 / 2 | 시간 0[s] | 손실 1.39\n",
      "| 에폭 185 |  반복 1 / 2 | 시간 0[s] | 손실 1.32\n",
      "| 에폭 186 |  반복 1 / 2 | 시간 0[s] | 손실 1.33\n",
      "| 에폭 187 |  반복 1 / 2 | 시간 0[s] | 손실 1.32\n",
      "| 에폭 188 |  반복 1 / 2 | 시간 0[s] | 손실 1.30\n",
      "| 에폭 189 |  반복 1 / 2 | 시간 0[s] | 손실 1.31\n",
      "| 에폭 190 |  반복 1 / 2 | 시간 0[s] | 손실 1.31\n",
      "| 에폭 191 |  반복 1 / 2 | 시간 0[s] | 손실 1.30\n",
      "| 에폭 192 |  반복 1 / 2 | 시간 0[s] | 손실 1.32\n",
      "| 에폭 193 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
      "| 에폭 194 |  반복 1 / 2 | 시간 0[s] | 손실 1.38\n",
      "| 에폭 195 |  반복 1 / 2 | 시간 0[s] | 손실 1.28\n",
      "| 에폭 196 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
      "| 에폭 197 |  반복 1 / 2 | 시간 0[s] | 손실 1.37\n",
      "| 에폭 198 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
      "| 에폭 199 |  반복 1 / 2 | 시간 0[s] | 손실 1.33\n",
      "| 에폭 200 |  반복 1 / 2 | 시간 0[s] | 손실 1.33\n",
      "| 에폭 201 |  반복 1 / 2 | 시간 0[s] | 손실 1.23\n",
      "| 에폭 202 |  반복 1 / 2 | 시간 0[s] | 손실 1.32\n",
      "| 에폭 203 |  반복 1 / 2 | 시간 0[s] | 손실 1.20\n",
      "| 에폭 204 |  반복 1 / 2 | 시간 0[s] | 손실 1.23\n",
      "| 에폭 205 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
      "| 에폭 206 |  반복 1 / 2 | 시간 0[s] | 손실 1.40\n",
      "| 에폭 207 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
      "| 에폭 208 |  반복 1 / 2 | 시간 0[s] | 손실 1.18\n",
      "| 에폭 209 |  반복 1 / 2 | 시간 0[s] | 손실 1.32\n",
      "| 에폭 210 |  반복 1 / 2 | 시간 0[s] | 손실 1.23\n",
      "| 에폭 211 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
      "| 에폭 212 |  반복 1 / 2 | 시간 0[s] | 손실 1.30\n",
      "| 에폭 213 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
      "| 에폭 214 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
      "| 에폭 215 |  반복 1 / 2 | 시간 0[s] | 손실 1.24\n",
      "| 에폭 216 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
      "| 에폭 217 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
      "| 에폭 218 |  반복 1 / 2 | 시간 0[s] | 손실 1.28\n",
      "| 에폭 219 |  반복 1 / 2 | 시간 0[s] | 손실 1.30\n",
      "| 에폭 220 |  반복 1 / 2 | 시간 0[s] | 손실 1.20\n",
      "| 에폭 221 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
      "| 에폭 222 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 223 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
      "| 에폭 224 |  반복 1 / 2 | 시간 0[s] | 손실 1.28\n",
      "| 에폭 225 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
      "| 에폭 226 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
      "| 에폭 227 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
      "| 에폭 228 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
      "| 에폭 229 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 230 |  반복 1 / 2 | 시간 0[s] | 손실 1.25\n",
      "| 에폭 231 |  반복 1 / 2 | 시간 0[s] | 손실 1.18\n",
      "| 에폭 232 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 233 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
      "| 에폭 234 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
      "| 에폭 235 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 236 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
      "| 에폭 237 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
      "| 에폭 238 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
      "| 에폭 239 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
      "| 에폭 240 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 241 |  반복 1 / 2 | 시간 0[s] | 손실 1.24\n",
      "| 에폭 242 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
      "| 에폭 243 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
      "| 에폭 244 |  반복 1 / 2 | 시간 0[s] | 손실 1.23\n",
      "| 에폭 245 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
      "| 에폭 246 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 247 |  반복 1 / 2 | 시간 0[s] | 손실 1.23\n",
      "| 에폭 248 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 249 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
      "| 에폭 250 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
      "| 에폭 251 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
      "| 에폭 252 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 253 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
      "| 에폭 254 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
      "| 에폭 255 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
      "| 에폭 256 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 257 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
      "| 에폭 258 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
      "| 에폭 259 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 260 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 261 |  반복 1 / 2 | 시간 0[s] | 손실 1.20\n",
      "| 에폭 262 |  반복 1 / 2 | 시간 0[s] | 손실 1.22\n",
      "| 에폭 263 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 264 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 265 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
      "| 에폭 266 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 267 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 268 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
      "| 에폭 269 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
      "| 에폭 270 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
      "| 에폭 271 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 272 |  반복 1 / 2 | 시간 0[s] | 손실 1.18\n",
      "| 에폭 273 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
      "| 에폭 274 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 275 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
      "| 에폭 276 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 277 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 278 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 279 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 280 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
      "| 에폭 281 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 282 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
      "| 에폭 283 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 284 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 285 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
      "| 에폭 286 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
      "| 에폭 287 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 288 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 289 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
      "| 에폭 290 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 291 |  반복 1 / 2 | 시간 0[s] | 손실 1.16\n",
      "| 에폭 292 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 293 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
      "| 에폭 294 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 295 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 296 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
      "| 에폭 297 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 298 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 299 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 300 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 301 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
      "| 에폭 302 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
      "| 에폭 303 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 304 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 305 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 306 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
      "| 에폭 307 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
      "| 에폭 308 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 309 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
      "| 에폭 310 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 311 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
      "| 에폭 312 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 313 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 314 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
      "| 에폭 315 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
      "| 에폭 316 |  반복 1 / 2 | 시간 0[s] | 손실 1.26\n",
      "| 에폭 317 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 318 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 319 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
      "| 에폭 320 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 321 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 322 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 323 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
      "| 에폭 324 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 325 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 326 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
      "| 에폭 327 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 328 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
      "| 에폭 329 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 330 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 331 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 332 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
      "| 에폭 333 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 334 |  반복 1 / 2 | 시간 0[s] | 손실 1.14\n",
      "| 에폭 335 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 336 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
      "| 에폭 337 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 338 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
      "| 에폭 339 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
      "| 에폭 340 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 341 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 342 |  반복 1 / 2 | 시간 0[s] | 손실 1.12\n",
      "| 에폭 343 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 344 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 345 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 346 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
      "| 에폭 347 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
      "| 에폭 348 |  반복 1 / 2 | 시간 0[s] | 손실 1.11\n",
      "| 에폭 349 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 350 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 351 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 352 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 353 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
      "| 에폭 354 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 355 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 356 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 357 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
      "| 에폭 358 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 359 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 360 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 361 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 362 |  반복 1 / 2 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 363 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 364 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 365 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 366 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 367 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
      "| 에폭 368 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 369 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 370 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 371 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
      "| 에폭 372 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 373 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 374 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 375 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 376 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 377 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 378 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 379 |  반복 1 / 2 | 시간 0[s] | 손실 1.20\n",
      "| 에폭 380 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 381 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 382 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
      "| 에폭 383 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 384 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 385 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
      "| 에폭 386 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 387 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 388 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 389 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 390 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
      "| 에폭 391 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
      "| 에폭 392 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 393 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 394 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 395 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 396 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 397 |  반복 1 / 2 | 시간 0[s] | 손실 1.21\n",
      "| 에폭 398 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 399 |  반복 1 / 2 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 400 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 401 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 402 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
      "| 에폭 403 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 404 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 405 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
      "| 에폭 406 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 407 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
      "| 에폭 408 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 409 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 410 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 411 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
      "| 에폭 412 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 413 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 414 |  반복 1 / 2 | 시간 0[s] | 손실 1.07\n",
      "| 에폭 415 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 416 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 417 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
      "| 에폭 418 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 419 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 420 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 421 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 422 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 423 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
      "| 에폭 424 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 425 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 426 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 427 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 428 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 429 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
      "| 에폭 430 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
      "| 에폭 431 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 432 |  반복 1 / 2 | 시간 0[s] | 손실 1.19\n",
      "| 에폭 433 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 434 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 435 |  반복 1 / 2 | 시간 0[s] | 손실 1.17\n",
      "| 에폭 436 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 437 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 438 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 439 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 440 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
      "| 에폭 441 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 442 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 443 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 444 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 445 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
      "| 에폭 446 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
      "| 에폭 447 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 448 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 449 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
      "| 에폭 450 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 451 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 452 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 453 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
      "| 에폭 454 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 455 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 456 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 457 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 458 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 459 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 460 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 461 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 462 |  반복 1 / 2 | 시간 0[s] | 손실 1.06\n",
      "| 에폭 463 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
      "| 에폭 464 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 465 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 466 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 467 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 468 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 469 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 470 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 471 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 472 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 473 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 474 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 475 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
      "| 에폭 476 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 477 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 478 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 479 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 480 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
      "| 에폭 481 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 482 |  반복 1 / 2 | 시간 0[s] | 손실 1.01\n",
      "| 에폭 483 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 484 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 485 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
      "| 에폭 486 |  반복 1 / 2 | 시간 0[s] | 손실 1.03\n",
      "| 에폭 487 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
      "| 에폭 488 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 489 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 490 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 491 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 492 |  반복 1 / 2 | 시간 0[s] | 손실 1.15\n",
      "| 에폭 493 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 494 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 495 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 496 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 497 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 498 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 499 |  반복 1 / 2 | 시간 0[s] | 손실 1.02\n",
      "| 에폭 500 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 501 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 502 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
      "| 에폭 503 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 504 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 505 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 506 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 507 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 508 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 509 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 510 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 511 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 512 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
      "| 에폭 513 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 514 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 515 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 516 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
      "| 에폭 517 |  반복 1 / 2 | 시간 0[s] | 손실 1.13\n",
      "| 에폭 518 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 519 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 520 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 521 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 522 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 523 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 524 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 525 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 526 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 527 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 528 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 529 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 530 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 531 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 532 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 533 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 534 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 535 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 536 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 537 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 538 |  반복 1 / 2 | 시간 0[s] | 손실 1.09\n",
      "| 에폭 539 |  반복 1 / 2 | 시간 0[s] | 손실 0.65\n",
      "| 에폭 540 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 541 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 542 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 543 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 544 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 545 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 546 |  반복 1 / 2 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 547 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 548 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 549 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 550 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 551 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 552 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 553 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
      "| 에폭 554 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 555 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 556 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 557 |  반복 1 / 2 | 시간 0[s] | 손실 0.99\n",
      "| 에폭 558 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
      "| 에폭 559 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 560 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 561 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 562 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
      "| 에폭 563 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 564 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 565 |  반복 1 / 2 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 566 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 567 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
      "| 에폭 568 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 569 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 570 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 571 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 572 |  반복 1 / 2 | 시간 0[s] | 손실 0.96\n",
      "| 에폭 573 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
      "| 에폭 574 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 575 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 576 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 577 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
      "| 에폭 578 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 579 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
      "| 에폭 580 |  반복 1 / 2 | 시간 0[s] | 손실 0.74\n",
      "| 에폭 581 |  반복 1 / 2 | 시간 0[s] | 손실 0.95\n",
      "| 에폭 582 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 583 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
      "| 에폭 584 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 585 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 586 |  반복 1 / 2 | 시간 0[s] | 손실 0.86\n",
      "| 에폭 587 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 588 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 589 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 590 |  반복 1 / 2 | 시간 0[s] | 손실 0.75\n",
      "| 에폭 591 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 592 |  반복 1 / 2 | 시간 0[s] | 손실 0.97\n",
      "| 에폭 593 |  반복 1 / 2 | 시간 0[s] | 손실 0.61\n",
      "| 에폭 594 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 595 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 596 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
      "| 에폭 597 |  반복 1 / 2 | 시간 0[s] | 손실 1.05\n",
      "| 에폭 598 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 599 |  반복 1 / 2 | 시간 0[s] | 손실 0.60\n",
      "| 에폭 600 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 601 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 602 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
      "| 에폭 603 |  반복 1 / 2 | 시간 0[s] | 손실 1.04\n",
      "| 에폭 604 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
      "| 에폭 605 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 606 |  반복 1 / 2 | 시간 0[s] | 손실 0.85\n",
      "| 에폭 607 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 608 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 609 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 610 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 611 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 612 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 613 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 614 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 615 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 616 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 617 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 618 |  반복 1 / 2 | 시간 0[s] | 손실 0.72\n",
      "| 에폭 619 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 620 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
      "| 에폭 621 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 622 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 623 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 624 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 625 |  반복 1 / 2 | 시간 0[s] | 손실 0.84\n",
      "| 에폭 626 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 627 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 628 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
      "| 에폭 629 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 630 |  반복 1 / 2 | 시간 0[s] | 손실 0.62\n",
      "| 에폭 631 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 632 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 633 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
      "| 에폭 634 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
      "| 에폭 635 |  반복 1 / 2 | 시간 0[s] | 손실 0.94\n",
      "| 에폭 636 |  반복 1 / 2 | 시간 0[s] | 손실 0.89\n",
      "| 에폭 637 |  반복 1 / 2 | 시간 0[s] | 손실 0.73\n",
      "| 에폭 638 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
      "| 에폭 639 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 640 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 641 |  반복 1 / 2 | 시간 0[s] | 손실 0.71\n",
      "| 에폭 642 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 643 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 644 |  반복 1 / 2 | 시간 0[s] | 손실 0.93\n",
      "| 에폭 645 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
      "| 에폭 646 |  반복 1 / 2 | 시간 0[s] | 손실 0.83\n",
      "| 에폭 647 |  반복 1 / 2 | 시간 0[s] | 손실 0.56\n",
      "| 에폭 648 |  반복 1 / 2 | 시간 0[s] | 손실 0.91\n",
      "| 에폭 649 |  반복 1 / 2 | 시간 0[s] | 손실 0.80\n",
      "| 에폭 650 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
      "| 에폭 651 |  반복 1 / 2 | 시간 0[s] | 손실 0.92\n",
      "| 에폭 652 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
      "| 에폭 653 |  반복 1 / 2 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 654 |  반복 1 / 2 | 시간 0[s] | 손실 0.67\n",
      "| 에폭 655 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 656 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
      "| 에폭 657 |  반복 1 / 2 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 658 |  반복 1 / 2 | 시간 0[s] | 손실 0.90\n",
      "| 에폭 659 |  반복 1 / 2 | 시간 0[s] | 손실 0.66\n",
      "| 에폭 660 |  반복 1 / 2 | 시간 0[s] | 손실 0.79\n",
      "| 에폭 661 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 662 |  반복 1 / 2 | 시간 0[s] | 손실 0.69\n",
      "| 에폭 663 |  반복 1 / 2 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 664 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 665 |  반복 1 / 2 | 시간 0[s] | 손실 0.82\n",
      "| 에폭 666 |  반복 1 / 2 | 시간 0[s] | 손실 0.88\n",
      "| 에폭 667 |  반복 1 / 2 | 시간 0[s] | 손실 0.70\n",
      "| 에폭 668 |  반복 1 / 2 | 시간 0[s] | 손실 0.76\n",
      "| 에폭 669 |  반복 1 / 2 | 시간 0[s] | 손실 0.78\n",
      "| 에폭 670 |  반복 1 / 2 | 시간 1[s] | 손실 0.78\n",
      "| 에폭 671 |  반복 1 / 2 | 시간 1[s] | 손실 0.78\n",
      "| 에폭 672 |  반복 1 / 2 | 시간 1[s] | 손실 0.71\n",
      "| 에폭 673 |  반복 1 / 2 | 시간 1[s] | 손실 0.89\n",
      "| 에폭 674 |  반복 1 / 2 | 시간 1[s] | 손실 0.78\n",
      "| 에폭 675 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
      "| 에폭 676 |  반복 1 / 2 | 시간 1[s] | 손실 0.88\n",
      "| 에폭 677 |  반복 1 / 2 | 시간 1[s] | 손실 0.78\n",
      "| 에폭 678 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 679 |  반복 1 / 2 | 시간 1[s] | 손실 0.88\n",
      "| 에폭 680 |  반복 1 / 2 | 시간 1[s] | 손실 0.79\n",
      "| 에폭 681 |  반복 1 / 2 | 시간 1[s] | 손실 0.67\n",
      "| 에폭 682 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
      "| 에폭 683 |  반복 1 / 2 | 시간 1[s] | 손실 0.79\n",
      "| 에폭 684 |  반복 1 / 2 | 시간 1[s] | 손실 0.90\n",
      "| 에폭 685 |  반복 1 / 2 | 시간 1[s] | 손실 0.53\n",
      "| 에폭 686 |  반복 1 / 2 | 시간 1[s] | 손실 0.79\n",
      "| 에폭 687 |  반복 1 / 2 | 시간 1[s] | 손실 0.97\n",
      "| 에폭 688 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
      "| 에폭 689 |  반복 1 / 2 | 시간 1[s] | 손실 0.77\n",
      "| 에폭 690 |  반복 1 / 2 | 시간 1[s] | 손실 0.69\n",
      "| 에폭 691 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
      "| 에폭 692 |  반복 1 / 2 | 시간 1[s] | 손실 0.87\n",
      "| 에폭 693 |  반복 1 / 2 | 시간 1[s] | 손실 0.67\n",
      "| 에폭 694 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
      "| 에폭 695 |  반복 1 / 2 | 시간 1[s] | 손실 0.70\n",
      "| 에폭 696 |  반복 1 / 2 | 시간 1[s] | 손실 0.97\n",
      "| 에폭 697 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 698 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
      "| 에폭 699 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
      "| 에폭 700 |  반복 1 / 2 | 시간 1[s] | 손실 0.80\n",
      "| 에폭 701 |  반복 1 / 2 | 시간 1[s] | 손실 0.73\n",
      "| 에폭 702 |  반복 1 / 2 | 시간 1[s] | 손실 0.86\n",
      "| 에폭 703 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
      "| 에폭 704 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 705 |  반복 1 / 2 | 시간 1[s] | 손실 0.82\n",
      "| 에폭 706 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
      "| 에폭 707 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
      "| 에폭 708 |  반복 1 / 2 | 시간 1[s] | 손실 0.78\n",
      "| 에폭 709 |  반복 1 / 2 | 시간 1[s] | 손실 0.73\n",
      "| 에폭 710 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 711 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 712 |  반복 1 / 2 | 시간 1[s] | 손실 0.79\n",
      "| 에폭 713 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 714 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
      "| 에폭 715 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 716 |  반복 1 / 2 | 시간 1[s] | 손실 0.61\n",
      "| 에폭 717 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 718 |  반복 1 / 2 | 시간 1[s] | 손실 0.85\n",
      "| 에폭 719 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
      "| 에폭 720 |  반복 1 / 2 | 시간 1[s] | 손실 0.78\n",
      "| 에폭 721 |  반복 1 / 2 | 시간 1[s] | 손실 0.70\n",
      "| 에폭 722 |  반복 1 / 2 | 시간 1[s] | 손실 0.67\n",
      "| 에폭 723 |  반복 1 / 2 | 시간 1[s] | 손실 0.85\n",
      "| 에폭 724 |  반복 1 / 2 | 시간 1[s] | 손실 0.71\n",
      "| 에폭 725 |  반복 1 / 2 | 시간 1[s] | 손실 0.67\n",
      "| 에폭 726 |  반복 1 / 2 | 시간 1[s] | 손실 0.82\n",
      "| 에폭 727 |  반복 1 / 2 | 시간 1[s] | 손실 0.62\n",
      "| 에폭 728 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
      "| 에폭 729 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 730 |  반복 1 / 2 | 시간 1[s] | 손실 0.69\n",
      "| 에폭 731 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
      "| 에폭 732 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 733 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
      "| 에폭 734 |  반복 1 / 2 | 시간 1[s] | 손실 0.78\n",
      "| 에폭 735 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 736 |  반복 1 / 2 | 시간 1[s] | 손실 0.78\n",
      "| 에폭 737 |  반복 1 / 2 | 시간 1[s] | 손실 0.73\n",
      "| 에폭 738 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 739 |  반복 1 / 2 | 시간 1[s] | 손실 0.77\n",
      "| 에폭 740 |  반복 1 / 2 | 시간 1[s] | 손실 0.80\n",
      "| 에폭 741 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
      "| 에폭 742 |  반복 1 / 2 | 시간 1[s] | 손실 0.58\n",
      "| 에폭 743 |  반복 1 / 2 | 시간 1[s] | 손실 0.77\n",
      "| 에폭 744 |  반복 1 / 2 | 시간 1[s] | 손실 0.83\n",
      "| 에폭 745 |  반복 1 / 2 | 시간 1[s] | 손실 0.69\n",
      "| 에폭 746 |  반복 1 / 2 | 시간 1[s] | 손실 0.55\n",
      "| 에폭 747 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
      "| 에폭 748 |  반복 1 / 2 | 시간 1[s] | 손실 0.94\n",
      "| 에폭 749 |  반복 1 / 2 | 시간 1[s] | 손실 0.57\n",
      "| 에폭 750 |  반복 1 / 2 | 시간 1[s] | 손실 0.83\n",
      "| 에폭 751 |  반복 1 / 2 | 시간 1[s] | 손실 0.61\n",
      "| 에폭 752 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 753 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 754 |  반복 1 / 2 | 시간 1[s] | 손실 0.78\n",
      "| 에폭 755 |  반복 1 / 2 | 시간 1[s] | 손실 0.71\n",
      "| 에폭 756 |  반복 1 / 2 | 시간 1[s] | 손실 0.77\n",
      "| 에폭 757 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 758 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
      "| 에폭 759 |  반복 1 / 2 | 시간 1[s] | 손실 0.70\n",
      "| 에폭 760 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 761 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
      "| 에폭 762 |  반복 1 / 2 | 시간 1[s] | 손실 0.70\n",
      "| 에폭 763 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
      "| 에폭 764 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
      "| 에폭 765 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
      "| 에폭 766 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
      "| 에폭 767 |  반복 1 / 2 | 시간 1[s] | 손실 0.77\n",
      "| 에폭 768 |  반복 1 / 2 | 시간 1[s] | 손실 0.55\n",
      "| 에폭 769 |  반복 1 / 2 | 시간 1[s] | 손실 0.86\n",
      "| 에폭 770 |  반복 1 / 2 | 시간 1[s] | 손실 0.60\n",
      "| 에폭 771 |  반복 1 / 2 | 시간 1[s] | 손실 0.64\n",
      "| 에폭 772 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
      "| 에폭 773 |  반복 1 / 2 | 시간 1[s] | 손실 0.69\n",
      "| 에폭 774 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 775 |  반복 1 / 2 | 시간 1[s] | 손실 0.70\n",
      "| 에폭 776 |  반복 1 / 2 | 시간 1[s] | 손실 0.64\n",
      "| 에폭 777 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 778 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 779 |  반복 1 / 2 | 시간 1[s] | 손실 0.64\n",
      "| 에폭 780 |  반복 1 / 2 | 시간 1[s] | 손실 0.64\n",
      "| 에폭 781 |  반복 1 / 2 | 시간 1[s] | 손실 0.69\n",
      "| 에폭 782 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 783 |  반복 1 / 2 | 시간 1[s] | 손실 0.69\n",
      "| 에폭 784 |  반복 1 / 2 | 시간 1[s] | 손실 0.58\n",
      "| 에폭 785 |  반복 1 / 2 | 시간 1[s] | 손실 0.80\n",
      "| 에폭 786 |  반복 1 / 2 | 시간 1[s] | 손실 0.63\n",
      "| 에폭 787 |  반복 1 / 2 | 시간 1[s] | 손실 0.64\n",
      "| 에폭 788 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
      "| 에폭 789 |  반복 1 / 2 | 시간 1[s] | 손실 0.64\n",
      "| 에폭 790 |  반복 1 / 2 | 시간 1[s] | 손실 0.83\n",
      "| 에폭 791 |  반복 1 / 2 | 시간 1[s] | 손실 0.64\n",
      "| 에폭 792 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 793 |  반복 1 / 2 | 시간 1[s] | 손실 0.69\n",
      "| 에폭 794 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 795 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 796 |  반복 1 / 2 | 시간 1[s] | 손실 0.63\n",
      "| 에폭 797 |  반복 1 / 2 | 시간 1[s] | 손실 0.67\n",
      "| 에폭 798 |  반복 1 / 2 | 시간 1[s] | 손실 0.84\n",
      "| 에폭 799 |  반복 1 / 2 | 시간 1[s] | 손실 0.48\n",
      "| 에폭 800 |  반복 1 / 2 | 시간 1[s] | 손실 0.88\n",
      "| 에폭 801 |  반복 1 / 2 | 시간 1[s] | 손실 0.41\n",
      "| 에폭 802 |  반복 1 / 2 | 시간 1[s] | 손실 0.88\n",
      "| 에폭 803 |  반복 1 / 2 | 시간 1[s] | 손실 0.57\n",
      "| 에폭 804 |  반복 1 / 2 | 시간 1[s] | 손실 0.78\n",
      "| 에폭 805 |  반복 1 / 2 | 시간 1[s] | 손실 0.57\n",
      "| 에폭 806 |  반복 1 / 2 | 시간 1[s] | 손실 0.67\n",
      "| 에폭 807 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 808 |  반복 1 / 2 | 시간 1[s] | 손실 0.77\n",
      "| 에폭 809 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 810 |  반복 1 / 2 | 시간 1[s] | 손실 0.57\n",
      "| 에폭 811 |  반복 1 / 2 | 시간 1[s] | 손실 0.73\n",
      "| 에폭 812 |  반복 1 / 2 | 시간 1[s] | 손실 0.67\n",
      "| 에폭 813 |  반복 1 / 2 | 시간 1[s] | 손실 0.67\n",
      "| 에폭 814 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 815 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 816 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 817 |  반복 1 / 2 | 시간 1[s] | 손실 0.70\n",
      "| 에폭 818 |  반복 1 / 2 | 시간 1[s] | 손실 0.57\n",
      "| 에폭 819 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
      "| 에폭 820 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 821 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 822 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 823 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 824 |  반복 1 / 2 | 시간 1[s] | 손실 0.60\n",
      "| 에폭 825 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
      "| 에폭 826 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 827 |  반복 1 / 2 | 시간 1[s] | 손실 0.49\n",
      "| 에폭 828 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
      "| 에폭 829 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
      "| 에폭 830 |  반복 1 / 2 | 시간 1[s] | 손실 0.55\n",
      "| 에폭 831 |  반복 1 / 2 | 시간 1[s] | 손실 0.79\n",
      "| 에폭 832 |  반복 1 / 2 | 시간 1[s] | 손실 0.61\n",
      "| 에폭 833 |  반복 1 / 2 | 시간 1[s] | 손실 0.58\n",
      "| 에폭 834 |  반복 1 / 2 | 시간 1[s] | 손실 0.71\n",
      "| 에폭 835 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
      "| 에폭 836 |  반복 1 / 2 | 시간 1[s] | 손실 0.75\n",
      "| 에폭 837 |  반복 1 / 2 | 시간 1[s] | 손실 0.58\n",
      "| 에폭 838 |  반복 1 / 2 | 시간 1[s] | 손실 0.61\n",
      "| 에폭 839 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
      "| 에폭 840 |  반복 1 / 2 | 시간 1[s] | 손실 0.58\n",
      "| 에폭 841 |  반복 1 / 2 | 시간 1[s] | 손실 0.71\n",
      "| 에폭 842 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
      "| 에폭 843 |  반복 1 / 2 | 시간 1[s] | 손실 0.47\n",
      "| 에폭 844 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
      "| 에폭 845 |  반복 1 / 2 | 시간 1[s] | 손실 0.51\n",
      "| 에폭 846 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
      "| 에폭 847 |  반복 1 / 2 | 시간 1[s] | 손실 0.47\n",
      "| 에폭 848 |  반복 1 / 2 | 시간 1[s] | 손실 0.64\n",
      "| 에폭 849 |  반복 1 / 2 | 시간 1[s] | 손실 0.83\n",
      "| 에폭 850 |  반복 1 / 2 | 시간 1[s] | 손실 0.50\n",
      "| 에폭 851 |  반복 1 / 2 | 시간 1[s] | 손실 0.83\n",
      "| 에폭 852 |  반복 1 / 2 | 시간 1[s] | 손실 0.53\n",
      "| 에폭 853 |  반복 1 / 2 | 시간 1[s] | 손실 0.56\n",
      "| 에폭 854 |  반복 1 / 2 | 시간 1[s] | 손실 0.80\n",
      "| 에폭 855 |  반복 1 / 2 | 시간 1[s] | 손실 0.46\n",
      "| 에폭 856 |  반복 1 / 2 | 시간 1[s] | 손실 0.70\n",
      "| 에폭 857 |  반복 1 / 2 | 시간 1[s] | 손실 0.56\n",
      "| 에폭 858 |  반복 1 / 2 | 시간 1[s] | 손실 0.63\n",
      "| 에폭 859 |  반복 1 / 2 | 시간 1[s] | 손실 0.60\n",
      "| 에폭 860 |  반복 1 / 2 | 시간 1[s] | 손실 0.72\n",
      "| 에폭 861 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
      "| 에폭 862 |  반복 1 / 2 | 시간 1[s] | 손실 0.63\n",
      "| 에폭 863 |  반복 1 / 2 | 시간 1[s] | 손실 0.52\n",
      "| 에폭 864 |  반복 1 / 2 | 시간 1[s] | 손실 0.62\n",
      "| 에폭 865 |  반복 1 / 2 | 시간 1[s] | 손실 0.69\n",
      "| 에폭 866 |  반복 1 / 2 | 시간 1[s] | 손실 0.55\n",
      "| 에폭 867 |  반복 1 / 2 | 시간 1[s] | 손실 0.69\n",
      "| 에폭 868 |  반복 1 / 2 | 시간 1[s] | 손실 0.55\n",
      "| 에폭 869 |  반복 1 / 2 | 시간 1[s] | 손실 0.79\n",
      "| 에폭 870 |  반복 1 / 2 | 시간 1[s] | 손실 0.52\n",
      "| 에폭 871 |  반복 1 / 2 | 시간 1[s] | 손실 0.64\n",
      "| 에폭 872 |  반복 1 / 2 | 시간 1[s] | 손실 0.69\n",
      "| 에폭 873 |  반복 1 / 2 | 시간 1[s] | 손실 0.62\n",
      "| 에폭 874 |  반복 1 / 2 | 시간 1[s] | 손실 0.45\n",
      "| 에폭 875 |  반복 1 / 2 | 시간 1[s] | 손실 0.69\n",
      "| 에폭 876 |  반복 1 / 2 | 시간 1[s] | 손실 0.64\n",
      "| 에폭 877 |  반복 1 / 2 | 시간 1[s] | 손실 0.61\n",
      "| 에폭 878 |  반복 1 / 2 | 시간 1[s] | 손실 0.49\n",
      "| 에폭 879 |  반복 1 / 2 | 시간 1[s] | 손실 0.63\n",
      "| 에폭 880 |  반복 1 / 2 | 시간 1[s] | 손실 0.70\n",
      "| 에폭 881 |  반복 1 / 2 | 시간 1[s] | 손실 0.61\n",
      "| 에폭 882 |  반복 1 / 2 | 시간 1[s] | 손실 0.42\n",
      "| 에폭 883 |  반복 1 / 2 | 시간 1[s] | 손실 0.78\n",
      "| 에폭 884 |  반복 1 / 2 | 시간 1[s] | 손실 0.53\n",
      "| 에폭 885 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 886 |  반복 1 / 2 | 시간 1[s] | 손실 0.60\n",
      "| 에폭 887 |  반복 1 / 2 | 시간 1[s] | 손실 0.63\n",
      "| 에폭 888 |  반복 1 / 2 | 시간 1[s] | 손실 0.58\n",
      "| 에폭 889 |  반복 1 / 2 | 시간 1[s] | 손실 0.53\n",
      "| 에폭 890 |  반복 1 / 2 | 시간 1[s] | 손실 0.67\n",
      "| 에폭 891 |  반복 1 / 2 | 시간 1[s] | 손실 0.60\n",
      "| 에폭 892 |  반복 1 / 2 | 시간 1[s] | 손실 0.52\n",
      "| 에폭 893 |  반복 1 / 2 | 시간 1[s] | 손실 0.77\n",
      "| 에폭 894 |  반복 1 / 2 | 시간 1[s] | 손실 0.50\n",
      "| 에폭 895 |  반복 1 / 2 | 시간 1[s] | 손실 0.70\n",
      "| 에폭 896 |  반복 1 / 2 | 시간 1[s] | 손실 0.42\n",
      "| 에폭 897 |  반복 1 / 2 | 시간 1[s] | 손실 0.68\n",
      "| 에폭 898 |  반복 1 / 2 | 시간 1[s] | 손실 0.59\n",
      "| 에폭 899 |  반복 1 / 2 | 시간 1[s] | 손실 0.59\n",
      "| 에폭 900 |  반복 1 / 2 | 시간 1[s] | 손실 0.61\n",
      "| 에폭 901 |  반복 1 / 2 | 시간 1[s] | 손실 0.50\n",
      "| 에폭 902 |  반복 1 / 2 | 시간 1[s] | 손실 0.59\n",
      "| 에폭 903 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 904 |  반복 1 / 2 | 시간 1[s] | 손실 0.51\n",
      "| 에폭 905 |  반복 1 / 2 | 시간 1[s] | 손실 0.69\n",
      "| 에폭 906 |  반복 1 / 2 | 시간 1[s] | 손실 0.50\n",
      "| 에폭 907 |  반복 1 / 2 | 시간 1[s] | 손실 0.59\n",
      "| 에폭 908 |  반복 1 / 2 | 시간 1[s] | 손실 0.59\n",
      "| 에폭 909 |  반복 1 / 2 | 시간 1[s] | 손실 0.67\n",
      "| 에폭 910 |  반복 1 / 2 | 시간 1[s] | 손실 0.59\n",
      "| 에폭 911 |  반복 1 / 2 | 시간 1[s] | 손실 0.56\n",
      "| 에폭 912 |  반복 1 / 2 | 시간 1[s] | 손실 0.41\n",
      "| 에폭 913 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
      "| 에폭 914 |  반복 1 / 2 | 시간 1[s] | 손실 0.60\n",
      "| 에폭 915 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 916 |  반복 1 / 2 | 시간 1[s] | 손실 0.51\n",
      "| 에폭 917 |  반복 1 / 2 | 시간 1[s] | 손실 0.66\n",
      "| 에폭 918 |  반복 1 / 2 | 시간 1[s] | 손실 0.40\n",
      "| 에폭 919 |  반복 1 / 2 | 시간 1[s] | 손실 0.76\n",
      "| 에폭 920 |  반복 1 / 2 | 시간 1[s] | 손실 0.49\n",
      "| 에폭 921 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
      "| 에폭 922 |  반복 1 / 2 | 시간 1[s] | 손실 0.58\n",
      "| 에폭 923 |  반복 1 / 2 | 시간 1[s] | 손실 0.50\n",
      "| 에폭 924 |  반복 1 / 2 | 시간 1[s] | 손실 0.74\n",
      "| 에폭 925 |  반복 1 / 2 | 시간 1[s] | 손실 0.49\n",
      "| 에폭 926 |  반복 1 / 2 | 시간 1[s] | 손실 0.56\n",
      "| 에폭 927 |  반복 1 / 2 | 시간 1[s] | 손실 0.59\n",
      "| 에폭 928 |  반복 1 / 2 | 시간 1[s] | 손실 0.57\n",
      "| 에폭 929 |  반복 1 / 2 | 시간 1[s] | 손실 0.56\n",
      "| 에폭 930 |  반복 1 / 2 | 시간 1[s] | 손실 0.58\n",
      "| 에폭 931 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
      "| 에폭 932 |  반복 1 / 2 | 시간 1[s] | 손실 0.48\n",
      "| 에폭 933 |  반복 1 / 2 | 시간 1[s] | 손실 0.48\n",
      "| 에폭 934 |  반복 1 / 2 | 시간 1[s] | 손실 0.55\n",
      "| 에폭 935 |  반복 1 / 2 | 시간 1[s] | 손실 0.57\n",
      "| 에폭 936 |  반복 1 / 2 | 시간 1[s] | 손실 0.57\n",
      "| 에폭 937 |  반복 1 / 2 | 시간 1[s] | 손실 0.56\n",
      "| 에폭 938 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
      "| 에폭 939 |  반복 1 / 2 | 시간 1[s] | 손실 0.56\n",
      "| 에폭 940 |  반복 1 / 2 | 시간 1[s] | 손실 0.56\n",
      "| 에폭 941 |  반복 1 / 2 | 시간 1[s] | 손실 0.47\n",
      "| 에폭 942 |  반복 1 / 2 | 시간 1[s] | 손실 0.56\n",
      "| 에폭 943 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
      "| 에폭 944 |  반복 1 / 2 | 시간 1[s] | 손실 0.56\n",
      "| 에폭 945 |  반복 1 / 2 | 시간 1[s] | 손실 0.46\n",
      "| 에폭 946 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
      "| 에폭 947 |  반복 1 / 2 | 시간 1[s] | 손실 0.57\n",
      "| 에폭 948 |  반복 1 / 2 | 시간 1[s] | 손실 0.47\n",
      "| 에폭 949 |  반복 1 / 2 | 시간 1[s] | 손실 0.53\n",
      "| 에폭 950 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
      "| 에폭 951 |  반복 1 / 2 | 시간 1[s] | 손실 0.48\n",
      "| 에폭 952 |  반복 1 / 2 | 시간 1[s] | 손실 0.63\n",
      "| 에폭 953 |  반복 1 / 2 | 시간 1[s] | 손실 0.54\n",
      "| 에폭 954 |  반복 1 / 2 | 시간 1[s] | 손실 0.65\n",
      "| 에폭 955 |  반복 1 / 2 | 시간 1[s] | 손실 0.37\n",
      "| 에폭 956 |  반복 1 / 2 | 시간 1[s] | 손실 0.63\n",
      "| 에폭 957 |  반복 1 / 2 | 시간 1[s] | 손실 0.55\n",
      "| 에폭 958 |  반복 1 / 2 | 시간 1[s] | 손실 0.57\n",
      "| 에폭 959 |  반복 1 / 2 | 시간 1[s] | 손실 0.46\n",
      "| 에폭 960 |  반복 1 / 2 | 시간 1[s] | 손실 0.63\n",
      "| 에폭 961 |  반복 1 / 2 | 시간 1[s] | 손실 0.55\n",
      "| 에폭 962 |  반복 1 / 2 | 시간 1[s] | 손실 0.62\n",
      "| 에폭 963 |  반복 1 / 2 | 시간 1[s] | 손실 0.45\n",
      "| 에폭 964 |  반복 1 / 2 | 시간 1[s] | 손실 0.45\n",
      "| 에폭 965 |  반복 1 / 2 | 시간 1[s] | 손실 0.56\n",
      "| 에폭 966 |  반복 1 / 2 | 시간 1[s] | 손실 0.54\n",
      "| 에폭 967 |  반복 1 / 2 | 시간 1[s] | 손실 0.63\n",
      "| 에폭 968 |  반복 1 / 2 | 시간 1[s] | 손실 0.55\n",
      "| 에폭 969 |  반복 1 / 2 | 시간 1[s] | 손실 0.34\n",
      "| 에폭 970 |  반복 1 / 2 | 시간 1[s] | 손실 0.64\n",
      "| 에폭 971 |  반복 1 / 2 | 시간 1[s] | 손실 0.61\n",
      "| 에폭 972 |  반복 1 / 2 | 시간 1[s] | 손실 0.56\n",
      "| 에폭 973 |  반복 1 / 2 | 시간 1[s] | 손실 0.42\n",
      "| 에폭 974 |  반복 1 / 2 | 시간 1[s] | 손실 0.56\n",
      "| 에폭 975 |  반복 1 / 2 | 시간 1[s] | 손실 0.54\n",
      "| 에폭 976 |  반복 1 / 2 | 시간 1[s] | 손실 0.62\n",
      "| 에폭 977 |  반복 1 / 2 | 시간 1[s] | 손실 0.44\n",
      "| 에폭 978 |  반복 1 / 2 | 시간 1[s] | 손실 0.63\n",
      "| 에폭 979 |  반복 1 / 2 | 시간 1[s] | 손실 0.41\n",
      "| 에폭 980 |  반복 1 / 2 | 시간 1[s] | 손실 0.56\n",
      "| 에폭 981 |  반복 1 / 2 | 시간 1[s] | 손실 0.53\n",
      "| 에폭 982 |  반복 1 / 2 | 시간 1[s] | 손실 0.60\n",
      "| 에폭 983 |  반복 1 / 2 | 시간 1[s] | 손실 0.53\n",
      "| 에폭 984 |  반복 1 / 2 | 시간 1[s] | 손실 0.52\n",
      "| 에폭 985 |  반복 1 / 2 | 시간 1[s] | 손실 0.55\n",
      "| 에폭 986 |  반복 1 / 2 | 시간 1[s] | 손실 0.43\n",
      "| 에폭 987 |  반복 1 / 2 | 시간 1[s] | 손실 0.60\n",
      "| 에폭 988 |  반복 1 / 2 | 시간 1[s] | 손실 0.53\n",
      "| 에폭 989 |  반복 1 / 2 | 시간 1[s] | 손실 0.45\n",
      "| 에폭 990 |  반복 1 / 2 | 시간 1[s] | 손실 0.62\n",
      "| 에폭 991 |  반복 1 / 2 | 시간 1[s] | 손실 0.43\n",
      "| 에폭 992 |  반복 1 / 2 | 시간 1[s] | 손실 0.62\n",
      "| 에폭 993 |  반복 1 / 2 | 시간 1[s] | 손실 0.59\n",
      "| 에폭 994 |  반복 1 / 2 | 시간 1[s] | 손실 0.33\n",
      "| 에폭 995 |  반복 1 / 2 | 시간 1[s] | 손실 0.64\n",
      "| 에폭 996 |  반복 1 / 2 | 시간 1[s] | 손실 0.40\n",
      "| 에폭 997 |  반복 1 / 2 | 시간 1[s] | 손실 0.64\n",
      "| 에폭 998 |  반복 1 / 2 | 시간 1[s] | 손실 0.42\n",
      "| 에폭 999 |  반복 1 / 2 | 시간 1[s] | 손실 0.59\n",
      "| 에폭 1000 |  반복 1 / 2 | 시간 1[s] | 손실 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eunbi\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:214: RuntimeWarning: Glyph 48152 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\eunbi\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:214: RuntimeWarning: Glyph 48373 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\eunbi\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:214: RuntimeWarning: Glyph 49552 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\eunbi\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:214: RuntimeWarning: Glyph 49892 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\eunbi\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:183: RuntimeWarning: Glyph 48152 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\eunbi\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:183: RuntimeWarning: Glyph 48373 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\eunbi\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:183: RuntimeWarning: Glyph 49552 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\eunbi\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:183: RuntimeWarning: Glyph 49892 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.trainer import Trainer\n",
    "from common.optimizer import Adam\n",
    "#from simple_cbow import SimpleCBOW\n",
    "from common.util import preprocess, create_contexts_target, convert_one_hot\n",
    "\n",
    "window_size = 1\n",
    "hidden_size = 5\n",
    "batch_size = 3\n",
    "max_epoch = 1000\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "contexts, target = create_contexts_target(corpus, window_size)\n",
    "target = convert_one_hot(target, vocab_size)\n",
    "contexts = convert_one_hot(contexts, vocab_size)\n",
    "\n",
    "model = simpleCBOW(vocab_size, hidden_size)\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "trainer.fit(contexts, target, max_epoch, batch_size)\n",
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you [-0.88570744 -0.9957745  -1.6699766   0.90276045 -0.9489839 ]\n",
      "say [ 1.1528203  0.7737249 -1.3374393 -1.1625279  1.1576147]\n",
      "goodbye [-1.0690522  -0.99726874 -0.01653015  0.9874587  -0.92388856]\n",
      "and [ 0.523455   1.9891618 -1.202602  -0.5396223  0.5409955]\n",
      "i [-1.0398458  -0.99237984 -0.01988868  0.9772534  -0.93040025]\n",
      "hello [-0.88631266 -0.9806779  -1.6627138   0.8935393  -0.9502012 ]\n",
      ". [ 1.3956754 -1.4012275 -1.0576149 -1.4291105  1.4262311]\n"
     ]
    }
   ],
   "source": [
    "# 밀집벡터: 단어의 분산표현\n",
    "\n",
    "word_vecs = model.word_vecs\n",
    "for word_id, word in id_to_word.items():\n",
    "    print(word, word_vecs[word_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 word2vec 보충\n",
    "### $P(w_t|w_{t-1}, w_{t+1})$\n",
    "- $w_{t-1}$과 $w_{t+1}$이 일어난 후 $w_t$가 일어날 확률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 확률과 언어 모델\n",
    "### $P(w_t|w_{t-1}, w_{t+1})$\n",
    "### $P(w_t|w_{t-2}, w_{t-1})$\n",
    "### $L=-logP(w_t|w_{t-2}, w_{t-1})$\n",
    "### $P(w_1, ..., w_m)=\\prod_{t=1}^m P(w_t|w_1, ..., w_{t-1})=\\prod_{t=1}^m P(w_t|w_{t-2}, w_{t-1})$\n",
    "\n",
    "\n",
    "## 5.2 RNN\n",
    "- RNN (Recurrent Neural Network): 순환 신경망\n",
    "### $h_t=RNN(x_t, h_{t-1})=tanh(h_{t-1}w_h+x_tw_x+b)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
